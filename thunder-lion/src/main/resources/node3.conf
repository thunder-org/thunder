node {
    cluster {
        name = "ThunderLion-Cluster"
    }
    master {
        id-issuer.timeout = 5
    }
}

akka {
    loglevel = INFO
    stdout-loglevel = INFO # When the actor system is starting up and shutting down the configured loggers are not used. Instead log messages are printed to stdout

    log-dead-letters = 0
    log-dead-letters-during-shutdown = off

    actor {
        provider = "akka.cluster.ClusterActorRefProvider"
        default-dispatcher {
            # Throughput for default Dispatcher, set to 1 for as fair as possible
            #throughput = 10
        }

        serializers {
            java = "akka.serialization.JavaSerializer"
            lion = "org.conqueror.lion.serialize.LionSerializer"
        }

        serialization-bindings {
            "java.io.Serializable" = java
            #"org.conqueror.lion.serialize.LionSerializable" = lion
            "org.conqueror.lion.message.LionMessage" = lion
            "akka.actor.ActorRef" = java
        }
    }

    remote {
        artery {
            enabled = on
            transport = aeron-udp
            canonical.hostname = "127.0.0.1"
            canonical.port = 39813
            advanced {
                # Maximum serialized message size, including header data.
                maximum-frame-size = 256 MiB
                flight-recorder {
                    enabled = off
                    destination = "data/artery/node3/artery.afr"
                }

                embedded-media-driver = on
                aeron-dir = "data/aeron/node3"
                # Whether to delete aeron embeded driver directory upon driver stop.
                delete-aeron-dir = yes
            }
        }
    }

    cluster {
        seed-nodes = [
            "akka://"${node.cluster.name}"@127.0.0.1:39813"
            , "akka://"${node.cluster.name}"@127.0.0.1:39811"
            , "akka://"${node.cluster.name}"@127.0.0.1:39812"
        ]
        roles = ["node-master"]

        role {
            node-master.min-nr-of-members = 1
        }

        singleton {
            # The actor name of the child singleton actor.
            singleton-name = "active"

            # Singleton among the nodes tagged with specified role.
            # If the role is not specified it's a singleton among all nodes in the cluster.
            role = "node-master"

            # When a node is becoming oldest it sends hand-over request to previous oldest,
            # that might be leaving the cluster. This is retried with this interval until
            # the previous oldest confirms that the hand over has started or the previous
            # oldest member is removed from the cluster (+ akka.cluster.down-removal-margin).
            hand-over-retry-interval = 1s

            # The number of retries are derived from hand-over-retry-interval and
            # akka.cluster.down-removal-margin (or ClusterSingletonManagerSettings.removalMargin),
            # but it will never be less than this property.
            min-number-of-hand-over-retries = 10
        }

        singleton-proxy {
            # The actor name of the singleton actor that is started by the ClusterSingletonManager
            singleton-name = ${akka.cluster.singleton.singleton-name}

            # The role of the cluster nodes where the singleton can be deployed.
            # If the role is not specified then any node will do.
            role = ${akka.cluster.singleton.role}

            # Interval at which the proxy will try to resolve the singleton instance.
            singleton-identification-interval = 1s

            # If the location of the singleton is unknown the proxy will buffer this
            # number of messages and deliver them when the singleton is identified.
            # When the buffer is full old messages will be dropped when new messages are
            # sent via the proxy.
            # Use 0 to disable buffering, i.e. messages will be dropped immediately if
            # the location of the singleton is unknown.
            # Maximum allowed buffer size is 10000.
            buffer-size = 1000
        }

        # Settings for the ClusterClientReceptionist extension
        client.receptionist {
            # Actor name of the ClusterReceptionist actor, /system/receptionist
            name = receptionist

            # Start the receptionist on members tagged with this role.
            # All members are used if undefined or empty.
            role = "node-master"

            # The receptionist will send this number of contact points to the client
            number-of-contacts = 3

            # The actor that tunnel response messages to the client will be stopped
            # after this time of inactivity.
            response-tunnel-receive-timeout = 30s

            # The id of the dispatcher to use for ClusterReceptionist actors.
            # If not specified default dispatcher is used.
            # If specified you need to define the settings of the actual dispatcher.
            use-dispatcher = ""

            # How often failure detection heartbeat messages should be received for
            # each ClusterClient
            heartbeat-interval = 10s

            # Number of potentially lost/delayed heartbeats that will be
            # accepted before considering it to be an anomaly.
            # The ClusterReceptionist is using the akka.remote.DeadlineFailureDetector, which
            # will trigger if there are no heartbeats within the duration
            # heartbeat-interval + acceptable-heartbeat-pause, i.e. 15 seconds with
            # the default settings.
            acceptable-heartbeat-pause = 13s

            # Failure detection checking interval for checking all ClusterClients
            failure-detection-interval = 2s
        }

        distributed-data {
            name = ddataReplicator
            durable {
                keys = ["DURABLE*"]
                store-actor-class = akka.cluster.ddata.LmdbDurableStore
                lmdb.dir = "data/ddata/node3"
                lmdb.map-size = 4 MiB
                lmdb.write-behind-interval = 200 ms
            }
        }

        # Disable legacy metrics in akka-cluster.
        metrics.enabled = off

        # Sigar native library extract location during tests.
        # Note: use per-jvm-instance folder when running multiple jvm on one host.
        metrics.native-library-extract-folder = ${user.dir}/target/native
    }

    extensions = [
        "akka.cluster.client.ClusterClientReceptionist"
    ]

}
